{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01 Cleaning.ipynb","provenance":[{"file_id":"1nyOU4TwSIfdTZLHopQGombW6rupGsjhW","timestamp":1619841923848}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8xL6eKLzDyFo"},"source":["## 1. Import data"]},{"cell_type":"code","metadata":{"id":"ygsDIqE_DyGl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622743973065,"user_tz":300,"elapsed":1377,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"631e7388-7be9-4782-a7b7-267066717cb2"},"source":["import pandas as pd\n","import os\n","import numpy as np\n","from google.colab import drive\n","import warnings\n","warnings.filterwarnings('ignore')\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Od05yCQeMvDf"},"source":["**File location**"]},{"cell_type":"code","metadata":{"id":"UYTix-pMFjxZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622743976544,"user_tz":300,"elapsed":143,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"744cf9c2-3c58-43c2-84c9-53b9c41cf3b5"},"source":["root_path = \"drive/MyDrive/ML_project\"\n","orig = root_path + \"/original_db\"\n","clean_p = root_path + \"/clean_db\"\n","os.listdir(orig)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['carac_viv.csv',\n"," 'carac_soc.csv',\n"," 'conjunto_de_datos_tb_sec_iii_endireh_2016.csv',\n"," 'rel_pareja_1.csv',\n"," 'rel_pareja_2.csv',\n"," 'toma_dec.csv',\n"," 'roles.csv',\n"," 'TB_SEC_III.dbf',\n"," 'GIS',\n"," 'DocumentacioÃÅn INEGI',\n"," 'conjunto_de_datos_tb_sec_vii_2_endireh_2016.csv',\n"," 'economico_mujer.csv',\n"," 'confianza.csv',\n"," 'rol_genero.csv']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"HtBukSHl8NBP"},"source":["**Importing data** "]},{"cell_type":"markdown","metadata":{"id":"JA6Ot3Id8VZr"},"source":["Source: https://www.inegi.org.mx/programas/endireh/2016/"]},{"cell_type":"code","metadata":{"id":"bUz9RQ_OFPqO"},"source":["rel_pareja_1 = pd.read_csv(orig + \"/rel_pareja_1.csv\", dtype='string')\n","rel_pareja_2 = pd.read_csv(orig + \"/rel_pareja_2.csv\", dtype='string')\n","rel_tviv = pd.read_csv(orig + \"/carac_viv.csv\", dtype='string')\n","rel_sdem = pd.read_csv(orig + \"/carac_soc.csv\", dtype={'ID_VIV': 'string','ID_MUJ': 'string', 'NOM_ENT':'string', 'NOM_MUN': 'string', \n","                                                'COD_RES_E': 'string', 'HOGAR': 'string', 'NOMBRE': 'string', 'NIV': 'string', \n","                                                'GRA': 'string', 'P2_8': 'string', 'P2_9': 'string', 'P2_10': 'string', \n","                                                'P2_11': 'string', 'P2_12': 'string', 'P2_13': 'string', 'P2_14': 'string', \n","                                                'P2_15': 'string', 'P2_16': 'string', 'CODIGO': 'string', \n","                                                'REN_MUJ_EL': 'string', 'REN_INF_AD': 'string', 'FN_DIA': 'string', \n","                                                'FN_MES': 'string', 'DOMINIO': 'string', 'COD_M15': 'string'})\n","rel_sdem = pd.read_csv(orig + \"/carac_soc.csv\", dtype={'ID_VIV': 'string','ID_MUJ': 'string', 'NOM_ENT':'string', 'NOM_MUN': 'string', \n","                                                'COD_RES_E': 'string', 'HOGAR': 'string', 'NOMBRE': 'string', 'NIV': 'string', \n","                                                'GRA': 'string', 'P2_8': 'string', 'P2_9': 'string', 'P2_10': 'string', \n","                                                'P2_11': 'string', 'P2_12': 'string', 'P2_13': 'string', 'P2_14': 'string', \n","                                                'P2_15': 'string', 'P2_16': 'string', 'CODIGO': 'string', \n","                                                'REN_MUJ_EL': 'string', 'REN_INF_AD': 'string', 'FN_DIA': 'string', \n","                                                'FN_MES': 'string', 'DOMINIO': 'string', 'COD_M15': 'string'})\n","rel_econ = pd.read_csv(orig + \"/economico_mujer.csv\", dtype='string')\n","\n","#roles and trust survey\n","rol_social = pd.read_csv(orig + \"/roles.csv\", dtype={'ID_VIV': 'string','ID_MUJ': 'string', 'DOMINIO': 'string', 'NOM_ENT': 'string',\n","                                                     'NOM_MUN': 'string', 'T_INSTRUM': 'string'})\n","rol_hogar = pd.read_csv(orig + \"/rol_genero.csv\", dtype={'ID_VIV': 'string','ID_MUJ': 'string', 'DOMINIO': 'string', 'NOM_ENT': 'string',\n","                                                     'NOM_MUN': 'string', 'T_INSTRUM': 'string'})\n","confianza = pd.read_csv(orig + \"/confianza.csv\", dtype={'ID_VIV': 'string','ID_MUJ': 'string', 'DOMINIO': 'string', 'NOM_ENT': 'string',\n","                                                     'NOM_MUN': 'string', 'T_INSTRUM': 'string'})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mD3HY2SEDEZa","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1622743441878,"user_tz":300,"elapsed":418,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"2a078f4e-0ec8-479f-e349-37a0d33dfa11"},"source":["#Creating a houshold ID\n","rel_sdem['id_hogar'] = rel_sdem.ID_VIV +rel_sdem.HOGAR\n","rel_sdem[[\"id_hogar\"]].describe() #Checking number of households is correct"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_hogar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>451548</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>126443</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>1300491.03\\r01\\r</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                id_hogar\n","count             451548\n","unique            126443\n","top     1300491.03\\r01\\r\n","freq                  21"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"HKbrk6G7DyGu"},"source":["# 2. Transforming to numeric"]},{"cell_type":"code","metadata":{"id":"ZhQkElW0DyGx"},"source":["#####Tranform columns to numeric\n","def clean(base, cols): \n","    '''\n","    Description:\n","        Takes a database and transforms all of its columns to numeric; with \n","        the exception of those columns specified in cols.\n","    Inputs:\n","        base (pd df): data\n","        cols (list of strs): contains the columns that will not be affected by the change\n","    Output: NO OUTPUT, will change the data in place\n","    ''' \n","    num_cols =  base.columns.to_list()\n","    for col in cols:\n","        num_cols.remove(col)\n","    base[num_cols] = base[num_cols].apply(pd.to_numeric, errors='coerce')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AD7yA_j8imL"},"source":["#Transform all columns to numeric except for these:\n","str_cols = ['ID_VIV', 'ID_MUJ', 'UPM', 'DOMINIO', 'NOM_ENT', 'NOM_MUN', 'T_INSTRUM']\n","str_cols_viv = ['ID_VIV', 'UPM', 'DOMINIO', 'NOM_ENT', 'NOM_MUN']\n","str_cols_econ = ['ID_VIV', 'ID_MUJ', 'UPM', 'DOMINIO', 'NOM_ENT', 'NOM_MUN', 'T_INSTRUM', 'P4_4']\n","str_cols_rolscoc = ['ID_VIV', 'ID_MUJ', 'VIV_SEL', 'PROG', 'HOGAR', 'UPM', 'DOMINIO', 'NOM_ENT', 'NOM_MUN', 'T_INSTRUM']\n","str_cols_conf = ['ID_VIV', 'ID_MUJ', 'UPM', 'VIV_SEL', 'PROG', 'HOGAR', 'DOMINIO', 'NOM_ENT', 'NOM_MUN', 'T_INSTRUM']\n","str_cols_rolhogar = ['ID_VIV', 'ID_MUJ', 'UPM', 'VIV_SEL', 'PROG', 'HOGAR', 'DOMINIO', 'NOM_ENT', 'NOM_MUN', 'T_INSTRUM']\n","\n","clean(rel_pareja_1, str_cols)\n","clean(rel_pareja_2, str_cols)\n","clean(rel_tviv, str_cols_viv)\n","clean(rel_econ, str_cols_econ)\n","clean(rol_social, str_cols_rolscoc)\n","clean(confianza, str_cols_conf)\n","clean(rol_hogar, str_cols_rolhogar)\n","\n","#Only transform these columns to numeric\n","sel_lst = [f'P2_{i}' for i in range(5, 17) if i != 7]\n","sel_lst.extend(['SEXO', 'EDAD', 'NIV', 'GRA'])\n","rel_sdem[sel_lst] = rel_sdem[sel_lst].apply(pd.to_numeric, errors='coerce')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1p-5M_mVAvWj"},"source":["# 3. Aggregate information from household members"]},{"cell_type":"code","metadata":{"id":"8N0EvTBCmWBa"},"source":["#Recode some missing values\n","rel_sdem['NIV'].replace(99, np.NAN, inplace = True)\n","rel_sdem['NIV'].replace(np.nan, rel_sdem['NIV'].median(), inplace=True)\n","rel_sdem['EDAD'].replace(99, np.NAN, inplace = True)\n","rel_sdem['EDAD'].replace(np.NAN, rel_sdem['EDAD'].median(), inplace = True)\n","rel_sdem['P2_15'].replace(np.NAN, 0, inplace=True)\n","rel_sdem['P2_10'].replace(np.NAN, 9, inplace=True)\n","rel_sdem['P2_13'].replace(np.NAN, 9, inplace=True)\n","\n","#Contruct new variables for sdem\n","rel_sdem['num_per_hog'] = rel_sdem.groupby('id_hogar')['id_hogar'].transform('count')\n","rel_sdem['num_mujeres_hog'] = (rel_sdem['SEXO'] == 2).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['mujeres_adultas'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['EDAD'] > 15)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['mujeres_no_adultas'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['EDAD'] < 15)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['secundaria_terminada'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['NIV'] >= 3)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['prepa_terminada'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['NIV'] >= 4)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['licenciatura_terminada'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['NIV'] >= 10)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['leer'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['P2_8'] < 2)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['num_indigenas'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['P2_10'] < 3)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['num_trabajadoras'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['P2_13'] < 2)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['max_educativo'] = rel_sdem[rel_sdem['NIV'] < 99][rel_sdem['SEXO'] == 2]['NIV'].groupby(rel_sdem['id_hogar']).transform('max')\n","rel_sdem['num_hombres_hog'] = (rel_sdem['SEXO'] == 1).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['hombres_adultos'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['EDAD'] > 15)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['hombres_no_adultos'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['EDAD'] < 15)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_secundaria_terminada'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['NIV'] >= 3)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_prepa_terminada'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['NIV'] >= 4)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_licenciatura_terminada'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['NIV'] >= 10)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_leer'] = ((rel_sdem['SEXO'] == 2) & (rel_sdem['P2_8'] < 1)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_num_indigenas'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['P2_10'] < 3)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['num_trabajadores'] = ((rel_sdem['SEXO'] == 1) & (rel_sdem['P2_13'] < 2)).groupby(rel_sdem['id_hogar']).transform('count')\n","rel_sdem['h_max_educativo'] = rel_sdem[rel_sdem['NIV'] < 99][rel_sdem['SEXO'] == 1]['NIV'].groupby(rel_sdem['id_hogar']).transform('max')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vn0kr8IQL2_r"},"source":["#Type of household\n","  #Nulls come from answer 2 in 1.8\n","  #Replace by 1.9 and 1.10 by 0 if \n","rel_tviv.replace(np.nan, 0, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2M9uebKAR34v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622743498456,"user_tz":300,"elapsed":2731,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"25f23ecd-1f33-4f34-e974-27326f2eaec6"},"source":["# Generating partners characteristics from sdem\n","  # First finding relationship of women to houshold boss. Var CODIGO = code of selected women\n","rel_sdem['CODIGO'].replace('\\r', '0\\r', inplace=True)\n","rel_sdem['CODIGO'].value_counts()\n","women_paren = rel_sdem[rel_sdem['CODIGO'] == '1\\r'][['id_hogar', 'PAREN']]\n","women_paren.rename(columns={'PAREN':'PAREN_W'}, inplace=True)\n","  # Merging with everyone in household\n","rel_sdem_p = rel_sdem.merge(women_paren, how='left',\n","                                      left_on= 'id_hogar', \n","                                      right_on= 'id_hogar', \n","                                      suffixes = (None,'_y'))\n","  # Generating partners\n","rel_sdem_p['woman-boss'] = (rel_sdem_p['PAREN_W'] == 1) & (rel_sdem_p['PAREN'] == 2) \n","rel_sdem_p['partner-boss'] = (rel_sdem_p['PAREN_W'] == 2) & (rel_sdem_p['PAREN'] == 1) \n","rel_sdem_p['partner'] = (rel_sdem_p['woman-boss'] == 1) | (rel_sdem_p['partner-boss'] == 1)\n","rel_sdem_p['partner'].value_counts() \n","  # Keep only partners\n","partners = rel_sdem_p[rel_sdem_p['partner'] == 1]\n","partners['p_sec_terminada'] = (partners['NIV'] >= 3)\n","partners['p_prepa_terminada'] = (partners['NIV'] >= 4)\n","partners['p_licenciatura_terminada'] = (partners['NIV'] >= 10)\n","partners['p_indigena'] = (partners['P2_10'] < 3)\n","partners['p_trabaja'] = (partners['P2_13'] < 2)\n","partners.rename(columns={'EDAD': 'p_edad', 'P2_15':'ocup_simple_h'}, inplace=True)\n","  # Merge with sdem general db by id_hogar\n","rel_sdem = rel_sdem.merge(partners[['id_hogar', 'p_sec_terminada', 'p_prepa_terminada',\n","                                    'p_licenciatura_terminada', 'p_indigena', 'p_trabaja', 'p_edad', 'ocup_simple_h']],\n","                          how='left', left_on='id_hogar', right_on='id_hogar')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ichqq2P_MS1l"},"source":["# 4. Merge data"]},{"cell_type":"code","metadata":{"id":"wfT3YtRSDyGy"},"source":["def drop_duplicates(data_base):\n","    '''\n","    Description:\n","        Deletes all columns that have a '_y' or '_x' at the end of its label. \n","        This is useful to avoid repeated columns in the database after a merge.\n","    Inputs:\n","        data_base (pd df): data\n","    Output: NO OUTPUT, will change the data in place\n","    ''' \n","    data_base.drop(data_base.filter(regex='_y$').columns.tolist(),axis=1, inplace=True)\n","    data_base.drop(data_base.filter(regex='_x$').columns.tolist(),axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnjuvKFQ8-Bf","executionInfo":{"status":"ok","timestamp":1622743513260,"user_tz":300,"elapsed":12384,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"8f5edd66-dfb2-42ae-e3cd-14354427dd93"},"source":["# Merge tables together into one master DB\n","data_base = rel_pareja_1.merge(rel_sdem, on= ['ID_MUJ', 'ID_VIV','CVE_MUN','CVE_ENT', 'FAC_VIV', 'FAC_MUJ'],\n","                               how='inner', suffixes = (None,'_y'))\n","\n","drop_duplicates(data_base)\n","data_base = data_base.merge(rel_econ, on= ['ID_MUJ', 'ID_VIV','CVE_MUN','CVE_ENT', 'FAC_VIV', 'FAC_MUJ'], \n","                            how='inner', suffixes = (None,'_y'))\n","\n","\n","drop_duplicates(data_base)\n","data_base = data_base.merge(rel_tviv, on= ['ID_VIV','CVE_MUN','CVE_ENT', 'FAC_VIV', 'ESTRATO'],\n","                            how='inner', suffixes = (None,'_y'))\n","\n","\n","drop_duplicates(data_base)\n","data_base = data_base.merge(rol_social, on= ['ID_MUJ', 'ID_VIV','CVE_MUN','CVE_ENT', 'FAC_VIV', 'FAC_MUJ'], \n","                            how='inner', suffixes = (None,'_y'))\n","\n","\n","drop_duplicates(data_base)\n","data_base = data_base.merge(confianza, on= ['ID_MUJ'], \n","                            how='inner', suffixes = (None,'_y'))\n","\n","\n","\n","drop_duplicates(data_base)\n","data_base = data_base.merge(rol_hogar, on= ['ID_MUJ'], \n","                            how='inner', suffixes = (None,'_y'))\n","\n","\n","drop_duplicates(data_base)\n","data_base['ID_MUJ'].dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StringDtype"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"jw_5Oi8YA8yz"},"source":["# 5. Final data wrangling: constructing new variables, renaming and dropping"]},{"cell_type":"markdown","metadata":{"id":"dwPvvdI1DyG1"},"source":["## Constructing a set of target variables"]},{"cell_type":"markdown","metadata":{"id":"TfUwHAiBFP5O"},"source":["We will construct three basic variables. First, one that measures the number type of violences that a women has suffered. Second, one that measures the number of violences that are more frequent. Thirdly, one that measures the violences that happen many times/often. \n","\n","Additionally, we construct these three variables for the four type of violences that are reported in this survey. Therefore, we end up having three variables for each of the four types of violence (3*4 = 12) + three variables that aggregate these types violences (3); for a total of 15."]},{"cell_type":"code","metadata":{"id":"8Q5RMoxDBRlU"},"source":["#Identify violence vars\n","violence_vars = data_base.filter(regex='^P13_1_',axis=1).columns\n","phys = ['P13_1_1', 'P13_1_2', 'P13_1_3', 'P13_1_4', 'P13_1_5', 'P13_1_6', 'P13_1_7', 'P13_1_8', 'P13_1_9']\n","psych = ['P13_1_10', 'P13_1_11', 'P13_1_12', 'P13_1_13', 'P13_1_14', 'P13_1_15', 'P13_1_16', 'P13_1_17', 'P13_1_18', 'P13_1_19', 'P13_1_20', 'P13_1_21', 'P13_1_22', 'P13_1_23AB', 'P13_1_24AB']\n","sex = ['P13_1_25', 'P13_1_26', 'P13_1_27', 'P13_1_28', 'P13_1_29']\n","econ = ['P13_1_30', 'P13_1_31', 'P13_1_32', 'P13_1_33AB', 'P13_1_34AB', 'P13_1_35AB', 'P13_1_36AB']\n","types_violence = [(\"phys\", phys), (\"psych\", psych), (\"sex\", sex), (\"econ\", econ)]\n","\n","#Counts the number of any violent episode\n","for tup in [(\"tot_violent\", 3), (\"tot_violent_few\", 2), (\"tot_violent_many\", 1)]:\n","  data_base[tup[0]] = 0\n","  for col in violence_vars:\n","    data_base[tup[0]] = data_base[tup[0]] + np.where(data_base[col] <= tup[1], 1, 0)\n","    for type in types_violence:\n","      data_base[tup[0] + \"_\" + type[0]] = 0\n","      for t in type[1]:\n","        data_base[tup[0] + \"_\" + type[0]] = data_base[tup[0] + \"_\" + type[0]] + np.where(data_base[t] <= tup[1], 1, 0)\n","#Final target\n","data_base['suffers_violence'] = (data_base['tot_violent'] > 0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6BXoDvzD2B9"},"source":["#Filter by women with a partner - only those in a free union or married will be relevant for our sample\n","data_base = data_base.loc[np.where((data_base['T_INSTRUM'] == 'A1\\r') | \n","                                   (data_base['T_INSTRUM'] == 'A2\\r'))]\n","                                   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBYVGGQo6783"},"source":["data_base.to_pickle(clean_p + \"/temp.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"493BkOnG02-A"},"source":["## Constructing features"]},{"cell_type":"code","metadata":{"id":"uZ51cbjRCa_t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622743531048,"user_tz":300,"elapsed":895,"user":{"displayName":"Antonia Sanhueza","photoUrl":"","userId":"11193007103929119931"}},"outputId":"20532378-81e3-4a00-d547-3c0100e05e8f"},"source":["data_base = pd.read_pickle(clean_p + \"/temp.pkl\")\n","#Numero de personas en la vivienda\n","data_base.rename(columns={'P1_7': 'num_per_viv'}, inplace=True)\n","#Ingreso de la mujer\n","data_base[\"P4_2\"] = data_base[\"P4_2\"].replace(999998, np.NAN)\n","data_base.loc[data_base[\"P4_1\"] == 1, \"P4_2\"] = data_base.loc[data_base[\"P4_1\"] == 1, \"P4_2\"]\n","data_base.loc[data_base[\"P4_2_1\"] == 1, \"P4_2\"] = data_base.loc[data_base[\"P4_2_1\"] == 1, \"P4_2\"]*4.2857\n","data_base.loc[data_base[\"P4_2_1\"] == 2, \"P4_2\"] = data_base.loc[data_base[\"P4_2_1\"] == 2, \"P4_2\"]*2\n","data_base.loc[data_base[\"P4_2_1\"] == 8, \"P4_2\"] = np.NAN\n","data_base.loc[data_base[\"P4_2_1\"] == 9, \"P4_2\"] = np.NAN\n","data_base[\"P4_2\"].replace(np.NAN, data_base[\"P4_2\"].median(), inplace=True )\n","data_base.rename(columns={'P4_2': 'ing_mens_m'}, inplace=True)\n","#Ocupacion del esposo\n","data_base.loc[data_base[\"P4_3\"] == 2, \"P4_4_CVE\"] = 0\n","data_base.rename(columns={'P4_4_CVE': 'ocup_h'}, inplace=True)\n","#Ingreso del esposo\n","data_base[\"P4_3\"] = data_base[\"P4_3\"].replace(2, 0)\n","data_base[\"P4_5_AB\"] = data_base[\"P4_5_AB\"].replace(999998, np.NAN)\n","data_base.loc[data_base[\"P4_3\"] == 1, \"P4_5_AB\"] = data_base.loc[data_base[\"P4_3\"] == 1, \"P4_5_AB\"]\n","  # weekly to monthly\n","data_base.loc[data_base[\"P4_5_1_AB\"] == 1, \"P4_5_AB\"] = data_base.loc[data_base[\"P4_5_1_AB\"] == 1, \"P4_3\"]*4.2857\n","  # biweekly to monthly\n","data_base.loc[data_base[\"P4_5_1_AB\"] == 2, \"P4_5_AB\"] = data_base.loc[data_base[\"P4_5_1_AB\"] == 2, \"P4_3\"]*2\n","data_base.loc[data_base[\"P4_5_1_AB\"] == 8, \"P4_5_AB\"] = np.NAN\n","#!! existe 9? \n","data_base.loc[data_base[\"P4_5_1_AB\"] == 9, \"P4_5_AB\"] = np.NAN\n","data_base.rename(columns={'P4_5_AB': 'ing_mens_h'}, inplace=True)\n","data_base['ing_mens_h'].replace(999998, np.NAN, inplace=True)\n","data_base['ing_mens_h'].replace(np.NAN, data_base['ing_mens_h'].median(), inplace=True)\n","\n","#Ownership of assets\n","for n in range(1,8):\n","  firstv = \"P4_12_\" + str(n)\n","  secv = \"P4_13_\" + str(n)\n","  data_base[secv].replace([3,4,5,6,7,8], 3, inplace=True)\n","  data_base[secv].replace(99, np.NAN, inplace=True)\n","  data_base[secv].replace(np.NAN, data_base[secv].mode()[0], inplace=True)\n","  data_base.loc[data_base[firstv] == 2, secv] = 0\n","  data_base.rename(columns={secv: \"asset_\" + str(n)}, inplace=True)\n","\n","#Knows how to read and write\n","data_base.loc[data_base[\"NIV\"] > 2, \"P2_8\"] = 1\n","data_base.loc[data_base[\"NIV\"] == 99, \"P2_8\"] = np.NAN\n","\n","\n","data_base[\"P2_8\"].replace(2, 0, inplace=True)\n","data_base.rename(columns={\"P2_8\": \"leer_escribir\"}, inplace=True)\n","data_base[\"leer_escribir\"].replace(np.nan, data_base[\"leer_escribir\"].median(),inplace=True)\n","\n","#Worked last week\n","data_base.loc[data_base[\"P2_13\"] == 2, \"P2_15\"] = 0\n","data_base.loc[data_base[\"P2_13\"] == 9, \"P2_15\"] = np.NAN\n","data_base.rename(columns={\"P2_15\": \"ocup_simple_m\"}, inplace=True)\n","data_base[\"ocup_simple_m\"].replace(np.nan, data_base[\"ocup_simple_m\"].median(),inplace=True)\n","data_base[\"ocup_simple_h\"].replace(np.nan, data_base[\"ocup_simple_h\"].median(),inplace=True)\n","\n","#Track variables that have already been formatted and could dropped\n","already_in_format = [\"P4_2_1\", \"P4_5_1_AB\", \"P4_4\", \"P4_12_1\",\n","                     \"P4_12_2\", \"P4_12_3\", \"P4_12_4\", \"P4_12_5\", \"P4_12_6\", \"P4_12_7\",\n","                     \"P2_13\", \"P2_14\"]\n","\n","#Education of woman\n","for educ in ['NIV', \"max_educativo\", \"h_max_educativo\"]:\n","  data_base[educ][data_base[educ].isin([5, 6, 7, 8, 9])] = 5\n","  data_base[educ][data_base[educ].isin([11])] = 10\n","  data_base[educ][data_base[educ].isin([1])] = 0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g9-vKWU5-SY5"},"source":["#Drop variables related to characteristics of help asked by women, after violent incident.\n","unused_viol = [col for col in data_base if col.startswith('P13_2')] + [col for col in data_base if col.startswith('P13_3')] + [col for col in data_base if col.startswith('P4_10_')]\n","data_base.drop([\"ocup_h\", 'COD_RES', 'COD_RES_MU','REN_M_ELE', 'num_renesp', 'P4AB_2', 'P4A_1', 'P4A_2', 'P4BC_3', 'P4BC_4', 'P4BC_5',\n","                'P4_2_1', 'P4_5_1_AB', 'P13_4', 'P13_5_1', 'P13_5_2', 'P13_5_3', 'P13_5_4', 'P13_5_5', 'P13_5_6', 'P13_5_7', 'P13_6', 'P13_7_1',\n","                'P13_7_2', 'P13_8_1', 'P13_8_2', 'P13_8_3', 'P13_8_4', 'P13_8_5', 'P13_8_6', 'P13_8_7', 'P13_8_8', 'P13_8_9', 'P13_8_10', \n","                'P13_8_11', 'P13_9_1_1', 'P13_9_1_2', 'P13_9_1_3', 'P13_10_1', 'P13_11_1', 'P13_12_1', 'P13_9_2_1', 'P13_9_2_2', 'P13_9_2_3',\n","                'P13_10_2', 'P13_11_2', 'P13_12_2','P13_9_3_1', 'P13_9_3_2', 'P13_9_3_3', 'P13_10_3', 'P13_11_3', 'P13_12_3', 'P13_9_4_1',\n","                'P13_9_4_2', 'P13_9_4_3', 'P13_10_4', 'P13_11_4', 'P13_12_4', 'P13_9_5_1', 'P13_9_5_2', 'P13_9_5_3', 'P13_10_5', 'P13_11_5',\n","                'P13_12_5', 'P13_9_6_1', 'P13_9_6_2', 'P13_9_6_3', 'P13_10_6', 'P13_11_6', 'P13_12_6', 'P13_9_7_1', 'P13_9_7_2', 'P13_9_7_3',\n","                'P13_10_7', 'P13_11_7', 'P13_12_7', 'P13_9_8_1', 'P13_9_8_2', 'P13_9_8_3', 'P13_10_8', 'P13_11_8', 'P13_12_8', 'P13_9_9_1',\n","                'P13_9_9_2', 'P13_9_9_3', 'P13_10_9', 'P13_11_9', \"P4_7_AB\", \"P4_9_6\", \"P2_12\", \"P4_9_7\", \"P4_9_4\", \"P4_9_1\", \n","                \"P4_9_3\", \"P4_9_2\", \"P4_9_8\", \"P4_9_5\", \"P1_10_1\", \"P1_10_2\", \"P1_10_4\", \"P1_10_3\", \"P1_9\", \"P4C_1\", \"P4BC_2\", 'P4_10_2_3',\n","                \"P4BC_1\", \"P4B_1\", \"P4B_2\", 'P16_3_1_2', 'P16_3_1_3', 'P16_3_2_2', 'P16_3_2_3', 'P16_3_3_2', 'P16_3_3_3', 'P16_3_4_2', 'P16_3_4_3',\n","                'P16_3_5_2', 'P16_3_5_3', 'P16_3_6_2', 'P16_3_6_3','P17_1_1_2', 'P17_1_1_3', 'P17_1_2_2', 'P17_1_2_3', 'P17_1_3_2', 'P17_1_3_3',\n","                'P17_1_4_2', 'P17_1_4_3', 'P17_1_5_2', 'P17_1_5_3', 'P17_1_6_2', 'P17_1_6_3', 'P17_1_7_2', 'P17_1_7_3'] + unused_viol + already_in_format, axis=1, inplace=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGmXw56yRrWy"},"source":["#Group columns so that we know how to treat and clean them. \n","dummies = ['P1_4_1', 'P1_4_2', 'P1_4_3', 'P1_4_4', 'P1_4_5', 'P1_4_6', 'P1_4_7', 'P1_4_8',\n","          'P1_8', 'P15_1_1', 'P15_1_2', 'P15_1_3', 'P15_1_4', 'P15_1_5', 'P15_1_6', 'P15_1_7', \"P15_1_8\", \"P15_1_9\",\n","          'P16_1_1', 'P16_1_2', 'P16_1_3', 'P16_1_4', 'P16_1_5', 'P16_1_6', 'P16_2_1', 'P16_2_2',\n","          'P16_2_3', 'P16_2_4', 'P16_2_5', 'P16_2_6', 'P4_1', 'P4_3', 'P4_8_1', 'P4_8_2', \n","          'P4_8_3', 'P4_8_4', 'P4_8_5', 'P4_8_6', 'P4_8_7', 'P4_8_8', 'P4_11', \"p_missing\"]\n","\n","special_cat = ['P4_6_AB','P16_3_1_1', 'P16_3_2_1', 'P16_3_3_1', 'P16_3_4_1', 'P16_3_5_1',\n","             'P16_3_6_1', \"P2_9\", \"P2_10\", \"P2_11\", \"P2_16\"]\n","\n","categoric = ['asset_1', 'asset_2', 'asset_3', 'asset_4', 'asset_5', 'asset_6', 'asset_7',\n","             'P1_1', 'P1_5', 'P1_6', 'P17_1_1_1', 'P17_1_2_1', 'P17_1_3_1', 'P17_1_4_1', 'P17_1_5_1',\n","             'P17_1_6_1', 'P17_1_7_1', \"PAREN\", \"NIV\", \"max_educativo\", \"P4AB_1\", \"ocup_simple_h\", \"p_sec_terminada\",\n","             \"p_prepa_terminada\", \"p_licenciatura_terminada\", \"p_indigena\", \"p_trabaja\", \"ocup_simple_m\"]\n","\n","numeric = ['P1_2', 'P1_3', 'EDAD', 'ing_mens_h', 'ing_mens_m', 'num_per_hog',\n","           'num_mujeres_hog', 'mujeres_adultas', 'mujeres_no_adultas', 'num_indigenas', \n","            'num_hombres_hog', 'hombres_adultos', 'hombres_no_adultos', \n","           'num_trabajadores', 'dif_edad', 'num_per_viv', 'P1_2_A', \"prepa_terminada\",\n","           \"licenciatura_terminada\", \"leer\", \"num_trabajadoras\", \"num_hombres_hog\", \"hombres_adultos\",\n","           \"hombres_no_adultos\", \"h_secundaria_terminada\",\t\"h_prepa_terminada\", \"h_licenciatura_terminada\",\n","           \"h_leer\", \"secundaria_terminada\", \"prepa_terminada\", \"licenciatura_terminada\",\n","           \"leer\", \"num_trabajadoras\", \"num_hombres_hog\", \"hombres_adultos\", \"hombres_no_adultos\", \n","           \"h_secundaria_terminada\", \"h_prepa_terminada\", \"h_licenciatura_terminada\", \"h_leer\",\n","           'num_trabajadoras', 'h_secundaria_terminada', 'leer_escribir']\n","\n","#This survey makes it hard to identify partners. About 6k of them were not identified. For those obs, \n","# we impute their missing values with a 99. These will be treated as a separate category. \n","for var in [ 'p_sec_terminada', 'p_prepa_terminada', 'p_licenciatura_terminada', \n","             'p_indigena', 'p_trabaja', 'ocup_simple_h']:\n","  data_base[var].fillna(99, inplace=True)\n","\n","#Generate a column that identifies those partners that we couldn't identify\n","data_base[\"p_missing\"] = data_base['p_edad'].isna()\n","\n","#Fill age with median value in case we don't have the actual value.\n","data_base[\"P1_3\"].replace([99], data_base[\"P1_3\"].median(), inplace=True)\n","data_base[\"EDAD\"].replace([98, 99], data_base[\"EDAD\"].median(), inplace=True)\n","data_base['p_edad'].fillna(data_base['p_edad'].median(), inplace=True)\n","data_base['dif_edad'] = abs(data_base['p_edad'] - data_base['EDAD'])\n","\n","#Make a dummy to see if the dad/mom of the women lives in the household\n","data_base[\"P2_6\"] = data_base[\"P2_6\"]<=30\n","data_base[\"P2_5\"] = data_base[\"P2_5\"]<=30\n","\n","#Impute dummie variables with mode\n","for col in dummies:\n","  data_base[col].replace([9, 98, np.nan], data_base[col].mode()[0], inplace=True)\n","  data_base[col].replace(2, 0, inplace=True)\n","\n","for col in categoric:\n","  data_base[col].replace([99, 98], data_base[col].mode()[0], inplace=True)\n","\n","#Special because is the only variable with 9 to replace\n","for col in special_cat:\n","  data_base[col].replace(9, data_base[col].mode()[0], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-IDHkoi-hEa"},"source":["data_base.to_pickle(clean_p + \"/MASTER_ENDIREH2016.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OWIqnPjKyJmG"},"source":["## (a) We save on DB that does one-hot encoding of dummies and categoricals"]},{"cell_type":"code","metadata":{"id":"z5RAgSLXxJpl"},"source":["for var in numeric:\n","  data_base[\"quant_\" + var ] = pd.qcut(data_base[var], 5, duplicates = \"drop\")\n","\n","quant = ['quant_P1_2', 'quant_P1_3', 'quant_EDAD', 'quant_ing_mens_h',\n","       'quant_ing_mens_m', 'quant_num_per_hog', 'quant_num_mujeres_hog',\n","       'quant_mujeres_adultas', 'quant_mujeres_no_adultas',\n","       'quant_num_indigenas', 'quant_num_trabajadoras',\n","       'quant_num_hombres_hog', 'quant_hombres_adultos',\n","       'quant_hombres_no_adultos', 'quant_num_trabajadores',\n","        'quant_dif_edad', 'quant_num_per_viv',\n","       'quant_P1_2_A', 'quant_prepa_terminada', 'quant_licenciatura_terminada',\n","       'quant_leer', 'quant_h_secundaria_terminada', 'quant_h_prepa_terminada',\n","       'quant_h_licenciatura_terminada', 'quant_h_leer',\n","       'quant_secundaria_terminada', 'quant_leer_escribir']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gqWINAFwZPwc"},"source":["#One-hot coding for dummies and categorical variables\n","\n","def df_with_dummies(df, cat_vars):\n","    '''\n","    Performs one-hot enconding of categorical variables\n","    Input:\n","        - df  (dataframe) containing the data\n","        - cat_vars (list) variables to turn into dummies\n","    Output:\n","        - df (dataframe) updated dataframe containing dummies for \n","            variables in dum_vars\n","    '''\n","    coded_features = []\n","    for col in cat_vars:\n","        dummy = pd.get_dummies(df[col].astype(str))\n","        col_names = {name: col + '_' + str(name) for name in dummy.columns}\n","        name_columns = col_names.values()\n","        coded_features.extend(name_columns)\n","        dummy.rename(columns=col_names, inplace=True)\n","        df = pd.concat([df, dummy], axis=1)\n","    \n","    return df.drop(columns=cat_vars), coded_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QE8L1kr-SYi"},"source":["data_base_coded, coded_features = df_with_dummies(data_base, categoric + special_cat + quant)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9likNX2F9wt"},"source":["#Creating polynomial features\n","def poly_features(X, y, threshold=0.5):\n","    '''\n","    Creates square or interaction features to input the model\n","    if the correlation of the interaction is higher than the feature alone\n","    and/or above a certain threshold, respectively.\n","    Input:\n","      - X: feature dataframe\n","      - y: target series\n","    Output:\n","      - poly_features dataframe containing polynomial features\n","    '''\n","    poly_features = pd.DataFrame()\n","    columns = X.columns\n","    #Interaction\n","    for i, var1 in enumerate(columns):\n","      for var2 in columns[i+1:]:\n","        interaction = str(var1) + '_' + str(var2)\n","        X[interaction] = X[var1] * X[var2]\n","        if abs(X[interaction].corr(y)) > threshold:\n","          print('classifies')\n","          poly_features[interaction] = X[interaction]\n","    print('out of first loop')\n","      #Squared\n","    for var in columns:\n","      sq = var+'_sq'\n","      X[sq] = X[var] * X[var] \n","      #print('Correlation is', X[interaction].corr(y) )\n","      if abs(X[sq].corr(y)) > threshold and \\\n","          abs(X[sq].corr(y)) > abs(X[var].corr(y)):  \n","        #print('classifies')\n","        poly_features[sq] = X[sq]\n","\n","    return poly_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSPRuoxm_ytK","outputId":"ca7706a5-3ca0-4bb7-f6f0-8c6e251d72f8"},"source":["variables = [ 'P2_5', 'P2_6', 'NIV_0.0', 'NIV_10.0', 'NIV_2.0', 'NIV_3.0', 'NIV_4.0', 'NIV_5.0',\n","            'ocup_simple_m_0.0', 'ocup_simple_m_1.0', 'ocup_simple_m_2.0', 'ocup_simple_m_3.0', 'ocup_simple_m_4.0', 'ocup_simple_m_5.0',\n","            'ocup_simple_m_6.0', 'P2_10_1.0', 'P2_10_2.0', 'P2_10_3.0', 'P2_10_8.0', \n","            'P4_1', 'P4_3', 'P4_8_1', 'P4_8_2', 'P4_8_3', 'P4_8_4', 'PAREN_1', 'PAREN_2', 'PAREN_3', 'PAREN_4', 'PAREN_5', 'PAREN_6', 'PAREN_7', 'PAREN_8', 'PAREN_9', 'P2_9_1.0', 'P2_9_2.0',\n","            'P4_8_5', 'P4_8_6', 'P4_8_7', 'P4_8_8', 'P4_11',  'P1_4_1', 'P1_4_2', 'P1_4_3', 'P1_4_4', 'P1_4_5', \n","            'P1_4_6', 'P1_4_7', 'P1_4_8', 'P1_4_9', 'P1_8', 'P15_1_1', 'P15_1_2', 'P15_1_3', 'P15_1_4', 'P15_1_5', 'P15_1_6', \n","            'P15_1_7', 'P15_1_8', 'P15_1_9', 'P16_1_1', 'P16_1_2', 'P16_1_3', 'P16_1_4', 'P16_1_5', 'P16_1_6', 'P16_2_1', 'P16_2_2', 'P16_2_3', \n","            'P16_2_4', 'P16_2_5', 'P16_2_6', 'asset_1_0.0', 'asset_1_1.0', 'asset_1_2.0', 'asset_1_3.0', 'asset_2_0.0', 'asset_2_1.0', 'asset_2_2.0',\n","            'asset_2_3.0', 'asset_3_0.0', 'asset_3_1.0', 'asset_3_2.0', 'asset_3_3.0', 'asset_4_0.0', 'asset_4_1.0', 'asset_4_2.0', 'asset_4_3.0',\n","            'asset_5_0.0', 'asset_5_1.0', 'asset_5_2.0', 'asset_5_3.0', 'asset_6_0.0', 'asset_6_1.0', 'asset_6_2.0', 'asset_6_3.0', 'asset_7_0.0', 'asset_7_1.0',\n","            'asset_7_2.0', 'asset_7_3.0', 'P1_1_1', 'P1_1_2', 'P1_1_3', 'P1_5_1', 'P1_5_2', 'P1_5_3', 'P1_5_4', 'P1_5_5', 'P1_5_6', 'P1_6_1', 'P1_6_2', 'P1_6_3',\n","            'P1_6_4', 'P1_6_5', 'P17_1_1_1_1', 'P17_1_1_1_10', 'P17_1_1_1_11', 'P17_1_1_1_12', 'P17_1_1_1_13', 'P17_1_1_1_14', 'P17_1_1_1_15', 'P17_1_1_1_2',\n","            'P17_1_1_1_3', 'P17_1_1_1_4', 'P17_1_1_1_5', 'P17_1_1_1_6', 'P17_1_1_1_7', 'P17_1_1_1_8', 'P17_1_1_1_9', 'P17_1_2_1_1', 'P17_1_2_1_10', 'P17_1_2_1_11', \n","            'P17_1_2_1_12', 'P17_1_2_1_13', 'P17_1_2_1_14', 'P17_1_2_1_15', 'P17_1_2_1_2', 'P17_1_2_1_3', 'P17_1_2_1_4', 'P17_1_2_1_5', 'P17_1_2_1_6', 'P17_1_2_1_7',\n","            'P17_1_2_1_8', 'P17_1_2_1_9', 'P17_1_3_1_1', 'P17_1_3_1_10', 'P17_1_3_1_11', 'P17_1_3_1_12', 'P17_1_3_1_13', 'P17_1_3_1_14', 'P17_1_3_1_15',\n","            'P17_1_3_1_2', 'P17_1_3_1_3', 'P17_1_3_1_4', 'P17_1_3_1_5', 'P17_1_3_1_6', 'P17_1_3_1_7', 'P17_1_3_1_8','P17_1_3_1_9', 'P17_1_4_1_1', 'P17_1_4_1_10', \n","            'P17_1_4_1_11', 'P17_1_4_1_12', 'P17_1_4_1_13', 'P17_1_4_1_14', 'P17_1_4_1_15', 'P17_1_4_1_2', 'P17_1_4_1_3', 'P17_1_4_1_4', 'P17_1_4_1_5', 'P17_1_4_1_6',\n","            'P17_1_4_1_7', 'P17_1_4_1_8', 'P17_1_4_1_9', 'P17_1_5_1_1', 'P17_1_5_1_10', 'P17_1_5_1_11', 'P17_1_5_1_12', 'P17_1_5_1_13', 'P17_1_5_1_14', 'P17_1_5_1_15',\n","            'P17_1_5_1_2', 'P17_1_5_1_3', 'P17_1_5_1_4', 'P17_1_5_1_5', 'P17_1_5_1_6', 'P17_1_5_1_7', 'P17_1_5_1_8', 'P17_1_5_1_9', 'P17_1_6_1_1', 'P17_1_6_1_10',\n","            'P17_1_6_1_11', 'P17_1_6_1_12', 'P17_1_6_1_13', 'P17_1_6_1_14', 'P17_1_6_1_15', 'P17_1_6_1_2', 'P17_1_6_1_3', 'P17_1_6_1_4', 'P17_1_6_1_5','P17_1_6_1_6',\n","            'P17_1_6_1_7', 'P17_1_6_1_8', 'P17_1_6_1_9', 'P17_1_7_1_1', 'P17_1_7_1_10', 'P17_1_7_1_11', 'P17_1_7_1_12', 'P17_1_7_1_13', 'P17_1_7_1_14', 'P17_1_7_1_15',\n","            'P17_1_7_1_2','P17_1_7_1_3', 'P17_1_7_1_4', 'P17_1_7_1_5', 'P17_1_7_1_6', 'P17_1_7_1_7', 'P17_1_7_1_8', 'P17_1_7_1_9', 'P4_6_AB_1.0', 'P4_6_AB_2.0', 'P4_6_AB_3.0',\n","             'P16_3_1_1_1', 'P16_3_1_1_2', 'P16_3_1_1_3', 'P16_3_1_1_4', 'P16_3_1_1_5', 'P16_3_1_1_6', 'P16_3_2_1_1', 'P16_3_2_1_2', 'P16_3_2_1_3', 'P2_11_1.0', 'P2_11_2.0',\n","            'P16_3_2_1_4', 'P16_3_2_1_5', 'P16_3_2_1_6', 'P16_3_3_1_1', 'P16_3_3_1_2', 'P16_3_3_1_3', 'P16_3_3_1_4', 'P16_3_3_1_5', 'P16_3_3_1_6', 'P16_3_4_1_1',\n","            'P16_3_4_1_2', 'P16_3_4_1_3', 'P16_3_4_1_4', 'P16_3_4_1_5', 'P16_3_4_1_6', 'P16_3_5_1_1', 'P16_3_5_1_2', 'P16_3_5_1_3', 'P16_3_5_1_4', 'P16_3_5_1_5',\n","            'P16_3_5_1_6', 'P16_3_6_1_1', 'P16_3_6_1_2', 'P16_3_6_1_3', 'P16_3_6_1_4', 'P16_3_6_1_5', 'P16_3_6_1_6', \n","            'max_educativo_0.0', 'max_educativo_10.0', 'max_educativo_2.0', 'max_educativo_3.0', 'max_educativo_4.0', 'max_educativo_5.0', 'quant_P1_2_(0.999, 2.0]', 'quant_P1_2_(2.0, 3.0]',\n","            'quant_P1_2_(3.0, 10.0]', 'quant_P1_3_(0.999, 4.0]',             'quant_P1_3_(4.0, 5.0]', 'quant_P1_3_(5.0, 6.0]',\n","            'quant_P1_3_(6.0, 9.0]', 'quant_P1_3_(9.0, 98.0]',             'quant_EDAD_(14.999, 28.0]', 'quant_EDAD_(28.0, 36.0]',\n","            'quant_EDAD_(36.0, 43.0]', 'quant_EDAD_(43.0, 54.0]',            'quant_EDAD_(54.0, 97.0]', 'quant_ing_mens_h_(-0.001, 4.286]',\n","            'quant_ing_mens_h_(4.286, 999999.0]', 'quant_ing_mens_m_(-0.001, 4000.0]',\n","            'quant_ing_mens_m_(4000.0, 4285687.143]', 'quant_num_per_hog_(0.999, 3.0]',\n","            'quant_num_per_hog_(3.0, 4.0]', 'quant_num_per_hog_(4.0, 5.0]',\n","            'quant_num_per_hog_(5.0, 21.0]', 'quant_num_mujeres_hog_(0.999, 3.0]',\n","            'quant_num_mujeres_hog_(3.0, 4.0]', 'quant_num_mujeres_hog_(4.0, 5.0]',\n","            'quant_num_mujeres_hog_(5.0, 21.0]', 'quant_mujeres_adultas_(0.999, 3.0]',\n","            'quant_mujeres_adultas_(3.0, 4.0]',             'quant_mujeres_adultas_(4.0, 5.0]',\n","            'quant_mujeres_adultas_(5.0, 21.0]',            'quant_mujeres_no_adultas_(0.999, 3.0]',\n","            'quant_mujeres_no_adultas_(3.0, 4.0]',             'quant_mujeres_no_adultas_(4.0, 5.0]',\n","            'quant_mujeres_no_adultas_(5.0, 21.0]',            'quant_num_indigenas_(0.999, 3.0]',\n","            'quant_num_indigenas_(3.0, 4.0]',             'quant_num_indigenas_(4.0, 5.0]',\n","            'quant_num_indigenas_(5.0, 21.0]',            'quant_num_trabajadoras_(0.999, 3.0]',\n","            'quant_num_trabajadoras_(3.0, 4.0]',            'quant_num_trabajadoras_(4.0, 5.0]',\n","            'quant_num_trabajadoras_(5.0, 21.0]',            'quant_num_hombres_hog_(0.999, 3.0]',\n","            'quant_num_hombres_hog_(3.0, 4.0]',            'quant_num_hombres_hog_(4.0, 5.0]',\n","            'quant_num_hombres_hog_(5.0, 21.0]',            'quant_hombres_adultos_(0.999, 3.0]',\n","            'quant_hombres_adultos_(3.0, 4.0]',\n","            'quant_hombres_adultos_(4.0, 5.0]',            'quant_hombres_adultos_(5.0, 21.0]',\n","            'quant_hombres_no_adultos_(0.999, 3.0]',            'quant_hombres_no_adultos_(3.0, 4.0]',\n","            'quant_hombres_no_adultos_(4.0, 5.0]',            'quant_hombres_no_adultos_(5.0, 21.0]',\n","            'quant_num_trabajadores_(0.999, 3.0]',            'quant_num_trabajadores_(3.0, 4.0]',\n","            'quant_num_trabajadores_(4.0, 5.0]',            'quant_num_trabajadores_(5.0, 21.0]',\n","            'quant_dif_edad_(-0.001, 1.0]',            'quant_dif_edad_(1.0, 3.0]',\n","            'quant_dif_edad_(3.0, 5.0]',            'quant_dif_edad_(5.0, 9.0]',\n","            'quant_dif_edad_(9.0, 77.0]',            'quant_num_per_viv_(0.999, 3.0]',\n","            'quant_num_per_viv_(3.0, 4.0]',            'quant_num_per_viv_(4.0, 5.0]',\n","            'quant_num_per_viv_(5.0, 25.0]',            'quant_P1_2_A_(0.999, 2.0]',\n","            'quant_P1_2_A_(2.0, 3.0]',            'quant_P1_2_A_(3.0, 4.0]',\n","            'quant_P1_2_A_(4.0, 5.0]',            'quant_P1_2_A_(5.0, 20.0]',\n","            'quant_prepa_terminada_(0.999, 3.0]',            'quant_prepa_terminada_(3.0, 4.0]',\n","            'quant_prepa_terminada_(4.0, 5.0]',            'quant_prepa_terminada_(5.0, 21.0]',\n","            'quant_licenciatura_terminada_(0.999, 3.0]',            'quant_licenciatura_terminada_(3.0, 4.0]',\n","            'quant_licenciatura_terminada_(4.0, 5.0]',            'quant_licenciatura_terminada_(5.0, 21.0]',\n","            'quant_leer_(0.999, 3.0]',            'quant_leer_(3.0, 4.0]',\n","            'quant_leer_(4.0, 5.0]',           'quant_leer_(5.0, 21.0]',\n","            'quant_h_secundaria_terminada_(0.999, 3.0]',            'quant_h_secundaria_terminada_(3.0, 4.0]',\n","            'quant_h_secundaria_terminada_(4.0, 5.0]',            'quant_h_secundaria_terminada_(5.0, 21.0]',\n","            'quant_h_prepa_terminada_(0.999, 3.0]',            'quant_h_prepa_terminada_(3.0, 4.0]',\n","            'quant_h_prepa_terminada_(4.0, 5.0]',           'quant_h_prepa_terminada_(5.0, 21.0]',\n","            'quant_h_licenciatura_terminada_(0.999, 3.0]',            'quant_h_licenciatura_terminada_(3.0, 4.0]',\n","            'quant_h_licenciatura_terminada_(4.0, 5.0]',            'quant_h_licenciatura_terminada_(5.0, 21.0]',\n","            'quant_h_leer_(0.999, 3.0]',            'quant_h_leer_(3.0, 4.0]',\n","            'quant_h_leer_(4.0, 5.0]',            'quant_h_leer_(5.0, 21.0]',\n","            'quant_secundaria_terminada_(0.999, 3.0]',            'quant_secundaria_terminada_(3.0, 4.0]',\n","            'quant_secundaria_terminada_(4.0, 5.0]',            'quant_secundaria_terminada_(5.0, 21.0]',\n","            'quant_leer_escribir_(-0.001, 1.0]', \"suffers_violence\"]\n","\n","features_data = data_base_coded[variables]\n","features_data.drop(columns='suffers_violence', inplace=True)\n","\n","poly_features(features_data, data_base['suffers_violence'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n","  f\"evaluating in Python space because the {repr(op_str)} \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8F125sZ9cMTr"},"source":["data_base_coded.to_pickle(clean_p + \"/MASTER_ENDIREH2016_coded_final.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"beJf2HwwD6BJ"},"source":[""],"execution_count":null,"outputs":[]}]}